{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unit.dataset_multiclass import get_dataloaders\n",
    "from unit.model import ContrastiveLearningModel\n",
    "from unit.config import config\n",
    "from datasets import load_from_disk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "from adapters import AutoAdapterModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaAdapterModel were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['heads.default.3.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/user_data/envs/adapter/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:208: Attribute 'adapter_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['adapter_model'])`.\n"
     ]
    }
   ],
   "source": [
    "pretrain_model = AutoAdapterModel.from_pretrained(config.MODEL_NAME)\n",
    "model = ContrastiveLearningModel(pretrain_model, \n",
    "                                learning_rate=config.LEARNING_RATE, \n",
    "                                weight_decay=config.WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unit.datasets import TextDataset, MultiLabelTextDataset\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "base_model_name = 'FacebookAI/roberta-large'\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name) # 加载预训练的模型和 tokenizer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測產生結果、多類別 Multi-Class\n",
    "def MultiClassPredit(model, dataloader, tokenizer, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    y_probas = []\n",
    "    preds = []\n",
    "    labels = []\n",
    "    texts = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            input_ids, attention_mask, label = [t.to(device) for t in batch]\n",
    "            # print(input_ids, attention_mask, label)\n",
    "            output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            pred = torch.argmax(output, dim=1)\n",
    "            y_proba = F.softmax(output, dim=-1)\n",
    "\n",
    "            preds.extend(pred.round().cpu().numpy())            \n",
    "            y_probas.extend(y_proba.cpu().numpy())\n",
    "            labels.extend(label.cpu().numpy())\n",
    "\n",
    "            #print(input_ids)\n",
    "            text = tokenizer.batch_decode(input_ids.cpu(),skip_special_tokens=True)\n",
    "            #print(text)\n",
    "            texts.extend(text)\n",
    "\n",
    "    return np.array(texts), np.array(y_probas), np.array(preds), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(base_model_name,test_texts,y_true,y_pred,test_probs,file_name='prediction.csv'):\n",
    "    output_dir = os.path.join(config.PROJECT_DIR,\n",
    "                                'models',\n",
    "                                config.PROJECT_NAME,\n",
    "                                'init',\n",
    "                                config.VERSION,\n",
    "                                config.CONTRASTIVE_STRATEGY, # random or mix                            \n",
    "                                base_model_name,\n",
    "                                'results')\n",
    "\n",
    "    # 保存结果到模型路径中的 results 目录\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    \n",
    "    prediction_df = pd.DataFrame([],columns=['text','y_pred','y_true','y_proba'])\n",
    "    \n",
    "    prediction_df['text'] = test_texts.tolist()    \n",
    "    prediction_df['y_pred'] = y_pred\n",
    "    prediction_df['y_true'] = y_true    \n",
    "    prediction_df['y_proba'] = test_probs.tolist()\n",
    "\n",
    "    \n",
    "    prediction_df.to_csv(f'{output_dir}/{file_name}',index=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行推理和评估\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "dataset_test = load_from_disk(f'{config.PROJECT_DIR}/data/NLP4IF2019/Encoder-based-hierarchical/test/dataset') \n",
    "test_texts = dataset_test['test']['text']\n",
    "test_labels = dataset_test['test']['classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_labels,columns=['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5079\n",
      "[3572, 330, 220, 545, 60, 61, 291]\n"
     ]
    }
   ],
   "source": [
    "classes_count = df['classes'].value_counts().sort_index(ascending=True).tolist()\n",
    "total_num = len(df)\n",
    "\n",
    "print(total_num)\n",
    "print(classes_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2967119511714904, 0.06497341996455995, 0.04331561330970664, 0.1073045875172278, 0.011813349084465446, 0.012010238235873204, 0.05729474305965741]\n",
      "[0.1758220122071274, 0.7012699350265801, 0.71751329001772, 0.6695215593620791, 0.7411399881866509, 0.7409923213230951, 0.707028942705257]\n"
     ]
    }
   ],
   "source": [
    "init_weight = [0.25,0.75,0.75,0.75,0.75,0.75,0.75]\n",
    "frequency_rate = [x/total_num for x in classes_count]\n",
    "frequency_rate[0] = 1-frequency_rate[0]\n",
    "print(frequency_rate)\n",
    "\n",
    "frequency_gap = [a*b for a,b in zip(frequency_rate,init_weight)]\n",
    "weight = [b-a for a,b in zip(frequency_gap,init_weight)]\n",
    "\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3cac3ae8244781b35d369a805d636c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1270 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "test_labels_encoder = label_encoder.fit_transform(test_labels)  \n",
    "\n",
    "# 创建数据集实例        \n",
    "test_dataset = TextDataset(test_texts, test_labels_encoder, tokenizer)\n",
    "\n",
    "# 创建 DataLoader\n",
    "num_workers = 19  # 设置 num_workers 参数以提高性能\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, num_workers=num_workers) \n",
    "\n",
    "# np.array(texts), np.array(y_probas), np.array(preds), np.array(labels)\n",
    "test_texts, test_probs, test_preds, test_labels  = MultiClassPredit(model, test_loader, tokenizer, device) \n",
    "\n",
    "y_pred = test_preds.astype(int).tolist()\n",
    "y_true = test_labels.tolist()\n",
    "\n",
    "save(base_model_name,test_texts,y_true,y_pred,test_probs,file_name='prediction_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11767/2724370218.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_labels' is not defined"
     ]
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'PersuTech'\n",
    "model_name_or_path = 'FacebookAI/roberta-large'\n",
    "task_name = \"init\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/user_data/envs/cyberbullying/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/user_data/envs/cyberbullying/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/user_data/envs/cyberbullying/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Class 0 Accuracy: 0.0377\n",
      "Class 1 Accuracy: 0.0000\n",
      "Class 2 Accuracy: 0.0000\n",
      "Class 3 Accuracy: 0.0000\n",
      "Class 4 Accuracy: 0.5510\n",
      "Class 5 Accuracy: 0.4364\n",
      "Class 6 Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} ../script/evaluate_multiclass.py --project {project} \\\n",
    "--task_name {task_name} \\\n",
    "--version 'v1' \\\n",
    "--strategy 'random' \\\n",
    "--base_model_name {model_name_or_path} \\\n",
    "--dataset_path_or_name 'prediction_total.csv' "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adapter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
